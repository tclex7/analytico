<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Analytico Hub</title>
    <link>/</link>
    <description>Recent content on Analytico Hub</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>My Name</copyright>
    <lastBuildDate>Fri, 10 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Covid-19 US County Visual in R</title>
      <link>/2020/04/10/2020-04-10-covid-19-us-county-visual-in-r/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/04/10/2020-04-10-covid-19-us-county-visual-in-r/</guid>
      <description>This tutorial will pull Covid-19 virus data by US County from New York Times.
Make sure correct packages are installed
if(!require(readr)) install.packages(&amp;quot;readr&amp;quot;, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;) if(!require(dplyr)) install.packages(&amp;quot;dplyr&amp;quot;, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;) if(!require(ggplot2)) install.packages(&amp;quot;ggplot2&amp;quot;, repos = &amp;quot;http://cran.us.r-project.org&amp;quot;) Load packages
library(readr) library(dplyr) library(ggplot2) Read data into R
covid &amp;lt;- read_csv(&amp;#39;https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv&amp;#39;) Select my County, we will use Los Angeles as an example.
mycounty &amp;lt;- &amp;#39;Los Angeles&amp;#39; Check make sure Los Angeles is part of the dataset, this will be a true or false.</description>
    </item>
    
    <item>
      <title>Replace Strings in R using str_replace</title>
      <link>/2020/03/21/2020-03-21-replace-strings-in-r-using-str-replace/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/03/21/2020-03-21-replace-strings-in-r-using-str-replace/</guid>
      <description>Replace Strings in R using str_replace 3rd party packages
library(stringr) library(readr) library(dplyr) Read in Data
head(df) ## # A tibble: 6 x 4 ## id dateAdded dateUpdated address ## &amp;lt;chr&amp;gt; &amp;lt;dttm&amp;gt; &amp;lt;dttm&amp;gt; &amp;lt;chr&amp;gt; ## 1 AVwc252WIN2L1WUfpqLP 2016-10-30 21:42:42 2018-09-10 21:06:27 5921 Valencia Cir ## 2 AVwc252WIN2L1WUfpqLP 2016-10-30 21:42:42 2018-09-10 21:06:27 5921 Valencia Cir ## 3 AVwc252WIN2L1WUfpqLP 2016-10-30 21:42:42 2018-09-10 21:06:27 5921 Valencia Cir ## 4 AVwdOclqIN2L1WUfti38 2015-11-28 19:19:35 2018-09-10 21:06:16 7520 Teague Rd ## 5 AVwdOclqIN2L1WUfti38 2015-11-28 19:19:35 2018-09-10 21:06:16 7520 Teague Rd ## 6 AVwdOclqIN2L1WUfti38 2015-11-28 19:19:35 2018-09-10 21:06:16 7520 Teague Rd Replace the first pattern in a single column</description>
    </item>
    
    <item>
      <title>Webscrape CDC Website with Python</title>
      <link>/2020/03/18/2020-03-18-webscrape-cdc-website-with-python/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/03/18/2020-03-18-webscrape-cdc-website-with-python/</guid>
      <description>Web Scraping CDC Website using lxml Note: The website URL has changed a couple times during the last month, you will have to update the url as well.
Import 3rd party packages. Use pip if you donâ€™t have them already installed.
import requests import datetime from lxml import html # url to scrape data from url = &amp;#39;https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html&amp;#39; # path to particular element path = &amp;#39;/html/body/div[7]/main/div[3]/div/div[3]/div[2]/div/div[1]/div/div[2]/ul&amp;#39; # get response object response = requests.</description>
    </item>
    
    <item>
      <title>Fantasy Football Analysis VLOOKUP in R</title>
      <link>/2020/03/17/2020-03-17-fantasy-football-analysis-vlookup-in-r/</link>
      <pubDate>Tue, 17 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/03/17/2020-03-17-fantasy-football-analysis-vlookup-in-r/</guid>
      <description>Packages used:
library(dplyr)
library(readxl)
library(ggplot2)
Data source: https://fantasydata.com/, uses non-ppr standard fantasy scoring
Read in Alvin Kamara and Mark Ingram 2018 data, both data sets are in same excel sheets but in different tabs. Kamara is on sheet 3 and Ingram on sheet 4. Use readxl package, and read_excel() function.
Kamara &amp;lt;- read_excel(akamara , sheet = 3) Mark_Ingram &amp;lt;- read_excel(mingram, sheet = 4) Using dplyr package filter games where A.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/page/about/</link>
      <pubDate>Fri, 03 Apr 2015 02:13:50 +0000</pubDate>
      
      <guid>/page/about/</guid>
      <description>About My name is Alex Cruz. I have been working as a data analyst since 2016. My favorite program to write code in is R, but also use Python and Julia.
School I attended the University of California, Berkeley and graduated in 2009.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/page/contact/</link>
      <pubDate>Fri, 03 Apr 2015 02:13:50 +0000</pubDate>
      
      <guid>/page/contact/</guid>
      <description>Contact Best way to contact me is via email at AnalyticoHub@gmail.com</description>
    </item>
    
    <item>
      <title>My awesome project</title>
      <link>/project/my-awesome-project/</link>
      <pubDate>Tue, 18 Nov 2014 02:13:50 +0000</pubDate>
      
      <guid>/project/my-awesome-project/</guid>
      <description>About project Aenean ipsum justo, semper eu nisl ut, pretium tincidunt sem. Praesent et diam sit amet lacus lobortis dictum a id lacus. Quisque hendrerit sit amet turpis eu varius. Ut id lorem ac felis ultrices tincidunt. Pellentesque consequat arcu ac fringilla imperdiet. Phasellus pellentesque, sapien non pulvinar blandit, sapien ante aliquet felis, vel porttitor sapien ante in lacus. Fusce non urna aliquet, malesuada nibh vel, luctus urna. Phasellus ut lacus molestie, varius purus quis, malesuada lorem.</description>
    </item>
    
  </channel>
</rss>